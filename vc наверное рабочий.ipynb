{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2K4pFE7zkajG"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YCd0MCl1YyG"
   },
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "  cleanr = re.compile('<.*?>')\n",
    "  cleantext = re.sub(cleanr, '', raw_html)\n",
    "  regex = re.compile('[^A-Za-zА-Яа-я]')\n",
    "  cleantext = regex.sub(' ', cleantext)\n",
    "  return cleantext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yp4SkBeEngT1"
   },
   "outputs": [],
   "source": [
    "##вроде работает для этого класса, но делает лист с листами\n",
    "def text(url):\n",
    "    page = requests.get('https://vc.ru/' + str(url))\n",
    "    soup = BeautifulSoup(page.text, 'html5lib')\n",
    "    text = ''\n",
    "    for item in soup.find_all('div',  class_=\"layout--с block-html\"):\n",
    "        text += item.text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ELd4rD2q1YyW"
   },
   "outputs": [],
   "source": [
    "def document(id):\n",
    "    page = requests.get('https://vc.ru/' + str(id) )\n",
    "    soup = BeautifulSoup(page.text, 'html5lib')\n",
    "    info = []\n",
    "    text =[]\n",
    "    lol = []\n",
    "    if soup.find(\"h1\", class_=\"content-header__title\") and 'Вакансия' not in soup.find('title').text:\n",
    "        #titledone\n",
    "        info.append(soup.find(\"h1\", class_=\"content-header__title\").text.strip())\n",
    "        #text\n",
    "        text = ' '\n",
    "        for i in soup.find_all('div',  class_=\"layout--с block-html\"):\n",
    "            text += i.text.strip()\n",
    "        if soup.find_all('div', class_=\"content content--full\"):\n",
    "            text += soup.find_all('div', class_=\"content content--full\")[0].find('div', class_=\"layout--a\").text.strip()\n",
    "        for i in soup.find_all(\"li\"):\n",
    "            text += i.text\n",
    "        info.append(text)\n",
    "        #yeardone\n",
    "        b = soup.find(\"time\", class_= \"time\").text.split()\n",
    "        c = b[1]\n",
    "        d = b[2]\n",
    "        if c == 'янв':\n",
    "            a = d + \"-\" +'01'\n",
    "            info.append(a)\n",
    "        elif c == 'фев':\n",
    "            a = d + \"-\" +'02'\n",
    "            info.append(a)\n",
    "        elif c == 'мар':\n",
    "            a = d + \"-\" +'03'\n",
    "            info.append(a)\n",
    "        elif c == 'апр':\n",
    "            a = d + \"-\" +'04'\n",
    "            info.append(a)\n",
    "        elif c == 'мая':\n",
    "            a = d + \"-\" +'05'\n",
    "            info.append(a)\n",
    "        elif c == 'июн':\n",
    "            a = d + \"-\" +'06'\n",
    "            info.append(a)\n",
    "        elif c == 'июл':\n",
    "            a = d + \"-\" +'07'\n",
    "            info.append(a)\n",
    "        elif c == 'авг':\n",
    "            a = d + \"-\" +'08'\n",
    "            info.append(a)\n",
    "        elif c == 'сен':\n",
    "            a = d + \"-\" +'09'\n",
    "            info.append(a)\n",
    "        elif c == 'окт':\n",
    "            a = d + \"-\" +'10'\n",
    "            info.append(a)\n",
    "        elif c == 'ноя':\n",
    "            a = d + \"-\" +'11'\n",
    "            info.append(a)\n",
    "        else:\n",
    "            a = d + \"-\" +'12'\n",
    "            info.append(a)\n",
    "        #sectiondone\n",
    "        info.append(soup.find(\"div\", class_=\n",
    "                              \"content-header-author__name\").text.strip())\n",
    "        #votesdone\n",
    "        a = soup.find(\"span\", class_=\"vote__value__v vote__value__v--real\").text\n",
    "        if a[0] == '–':\n",
    "            b = int(a[1:])\n",
    "            info.append(-b)\n",
    "        else:\n",
    "            info.append(int(a))\n",
    "        #viewsdone\n",
    "        info.append(soup.find(\"span\", class_=\"views__value\").text.replace(u'\\xa0', u''))\n",
    "        #bookmarksdone\n",
    "        if soup.find('div',\n",
    "                        class_=\"favorite_marker favorite_marker--type-content favorite_marker--non_zero\"):\n",
    "            info.append(int(soup.find('div',\n",
    "                        class_=\"favorite_marker favorite_marker--type-content favorite_marker--non_zero\").text.split()[0]))\n",
    "        else:\n",
    "            info.append(0)\n",
    "        #commentsdone\n",
    "        comment1 = soup.find_all(\"div\", class_=\"comments__item__text\")\n",
    "        comments = ' '\n",
    "        for i in range(len(comment1)):\n",
    "            if comment1[i].text != 'Комментарий удален':\n",
    "                comments += '~#' + comment1[i].text\n",
    "        info.append(comments)\n",
    "    else:\n",
    "        info.append('NaN')\n",
    "    print(id)\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ee5DzWi4_PKo"
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "with Pool(100) as p:\n",
    "    a = p.map(document, np.arange(100000,100101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vkItn0BJ36EG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110342\n",
      "110343\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(a, columns=['title', 'text', 'date', 'section', 'votes', 'views', 'bookmarks', 'comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "506KuFdx17Ps"
   },
   "outputs": [],
   "source": [
    "i = 239400\n",
    "for j in range(239500, 351001, 100):\n",
    "    from multiprocessing import Pool\n",
    "    with Pool(100) as p:\n",
    "        b = p.map(document, np.arange(i, j))\n",
    "    try:\n",
    "        df = pd.DataFrame(b, columns=['title', 'text', 'date', 'hubs', 'tags', 'votes', 'views', 'bookmarks', 'comments'])\n",
    "        df.to_feather(str(i) + \"-\" + str(j) + '.feather')\n",
    "        from google.colab import files\n",
    "        files.download(str(i) + \"-\" + str(j) + '.feather')\n",
    "        print('done', i, j)\n",
    "    except:\n",
    "        print('ooops')\n",
    "    i += 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6r0ilDlG1Yyl"
   },
   "outputs": [],
   "source": [
    "df.to_csv('vcru.csv')\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "from google.colab import files\n",
    "files.download('vcru.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "vc.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
