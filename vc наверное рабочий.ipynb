{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vc наверное рабочий.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2K4pFE7zkajG",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-YCd0MCl1YyG",
        "colab": {}
      },
      "source": [
        "def cleanhtml(raw_html):\n",
        "  cleanr = re.compile('<.*?>')\n",
        "  cleantext = re.sub(cleanr, '', raw_html)\n",
        "  regex = re.compile('[^A-Za-zА-Яа-я]')\n",
        "  cleantext = regex.sub(' ', cleantext)\n",
        "  return cleantext"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jXvwPGZ3F1E",
        "colab_type": "text"
      },
      "source": [
        "### Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yp4SkBeEngT1",
        "colab": {}
      },
      "source": [
        "##вроде работает для этого класса\n",
        "def text(url):\n",
        "    page = requests.get('https://vc.ru/' + str(url))\n",
        "    soup = BeautifulSoup(page.text, 'html5lib')\n",
        "    text = ''\n",
        "    for item in soup.find_all('div',  class_=\"layout--с block-html\"):\n",
        "        text += item.text\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ELd4rD2q1YyW",
        "colab": {}
      },
      "source": [
        "def document(id):\n",
        "    page = requests.get('https://vc.ru/' + str(id) )\n",
        "    soup = BeautifulSoup(page.text, 'html5lib')\n",
        "    info = []\n",
        "    text =[]\n",
        "    lol = []\n",
        "    if soup.find(\"h1\", class_=\"content-header__title\") and 'Вакансия' not in soup.find('title').text:\n",
        "        #titledone\n",
        "        info.append(soup.find(\"h1\", class_=\"content-header__title\").text.strip())\n",
        "        #text\n",
        "        text = ' '\n",
        "        for i in soup.find_all('div',  class_=\"layout--с block-html\"):\n",
        "            text += i.text.strip()\n",
        "        for i in soup.find_all(\"li\"):\n",
        "            text += i.text\n",
        "        info.append(text)\n",
        "        #date\n",
        "        b = soup.find(\"time\", class_= \"time\").text.split()\n",
        "        c = b[1]\n",
        "        d = b[2]\n",
        "        if c == 'янв':\n",
        "            a = d + \"-\" +'01'\n",
        "            info.append(a)\n",
        "        elif c == 'фев':\n",
        "            a = d + \"-\" +'02'\n",
        "            info.append(a)\n",
        "        elif c == 'мар':\n",
        "            a = d + \"-\" +'03'\n",
        "            info.append(a)\n",
        "        elif c == 'апр':\n",
        "            a = d + \"-\" +'04'\n",
        "            info.append(a)\n",
        "        elif c == 'мая':\n",
        "            a = d + \"-\" +'05'\n",
        "            info.append(a)\n",
        "        elif c == 'июн':\n",
        "            a = d + \"-\" +'06'\n",
        "            info.append(a)\n",
        "        elif c == 'июл':\n",
        "            a = d + \"-\" +'07'\n",
        "            info.append(a)\n",
        "        elif c == 'авг':\n",
        "            a = d + \"-\" +'08'\n",
        "            info.append(a)\n",
        "        elif c == 'сен':\n",
        "            a = d + \"-\" +'09'\n",
        "            info.append(a)\n",
        "        elif c == 'окт':\n",
        "            a = d + \"-\" +'10'\n",
        "            info.append(a)\n",
        "        elif c == 'ноя':\n",
        "            a = d + \"-\" +'11'\n",
        "            info.append(a)\n",
        "        else:\n",
        "            a = d + \"-\" +'12'\n",
        "            info.append(a)\n",
        "        #sectiondone\n",
        "        info.append(soup.find(\"div\", class_=\n",
        "                              \"content-header-author__name\").text.strip())\n",
        "        #votesdone\n",
        "        a = soup.find(\"span\", class_=\"vote__value__v vote__value__v--real\").text\n",
        "        if a[0] == '–':\n",
        "            b = int(a[1:])\n",
        "            info.append(-b)\n",
        "        else:\n",
        "            info.append(int(a))\n",
        "        #viewsdone\n",
        "        info.append(soup.find(\"span\", class_=\"views__value\").text.replace(u'\\xa0', u''))\n",
        "        #bookmarksdone\n",
        "        if soup.find('div',\n",
        "                        class_=\"favorite_marker favorite_marker--type-content favorite_marker--non_zero\"):\n",
        "            info.append(int(soup.find('div',\n",
        "                        class_=\"favorite_marker favorite_marker--type-content favorite_marker--non_zero\").text.split()[0]))\n",
        "        else:\n",
        "            info.append(0)\n",
        "        #commentsdone\n",
        "        comment1 = soup.find_all(\"div\", class_=\"comments__item__text\")\n",
        "        comments = ' '\n",
        "        for i in range(len(comment1)):\n",
        "            if comment1[i].text != 'Комментарий удален':\n",
        "                comments += '~#' + comment1[i].text\n",
        "        info.append(comments)\n",
        "    else:\n",
        "        info.append('NaN')\n",
        "    print(id)\n",
        "    return info"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAinGPnqk4Qi",
        "colab_type": "text"
      },
      "source": [
        "пока не работает"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDT-eO016iIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "page = requests.get('https://vc.ru/3456' )\n",
        "soup = BeautifulSoup(page.text, 'html5lib')\n",
        "info = []\n",
        "text =[]\n",
        "text += soup.find_all('div', class_=\"content content--full\")[0].find('div', class_=\"layout--a \").text.strip()\n",
        "text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tZF1IdRk-Oc",
        "colab_type": "text"
      },
      "source": [
        "вот здесь пропускает очень много"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ9ZxbpEckjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from multiprocessing import Pool\n",
        "with Pool(100) as p:\n",
        "      b = p.map(document, np.arange(2610, 2900))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iza_TI4ReJuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vkItn0BJ36EG",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(b, columns=['title', 'text', 'date', 'section', 'votes', 'views', 'bookmarks', 'comments'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69Ra_I1L3F1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0quUSmvtlJb7",
        "colab_type": "text"
      },
      "source": [
        "уже для загрузки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "506KuFdx17Ps",
        "colab": {}
      },
      "source": [
        "i = 2600\n",
        "for j in range(2700, 110000, 100):\n",
        "    from multiprocessing import Pool\n",
        "    with Pool(100) as p:\n",
        "        b = p.map(document, np.arange(i, j))\n",
        "    try:\n",
        "        df = pd.DataFrame(b, columns=['title', 'text', 'date', 'section', 'votes', 'views', 'bookmarks', 'comments'])\n",
        "        df.to_feather(str(i) + \"-\" + str(j) + '.feather')\n",
        "        from google.colab import files\n",
        "        files.download(str(i) + \"-\" + str(j) + '.feather')\n",
        "        print('done', i, j)\n",
        "    except:\n",
        "        print('ooops')\n",
        "    i += 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6r0ilDlG1Yyl",
        "colab": {}
      },
      "source": [
        "df.to_csv('vcru.csv')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('vcru.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}